{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHxsdJRrU-X7",
        "outputId": "15e2bb9f-159e-4782-cd22-e41fc658f71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from whisper) (1.16.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41121 sha256=f5d2af341832bac5fe04e694ada6ea47351cc3fd414dc5644e6786d6f58e8644\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/7c/1d/015619716e2facae6631312503baf3c3220e6a9a3508cb14b6\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n",
            "Collecting openai-whisper==20230117\n",
            "  Downloading openai-whisper-20230117.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230117) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230117) (4.66.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230117) (10.1.0)\n",
            "Collecting transformers>=4.19.0 (from openai-whisper==20230117)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper==20230117)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230117) (0.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230117) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.19.0->openai-whisper==20230117)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230117) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230117) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230117) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230117) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.19.0->openai-whisper==20230117)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.19.0->openai-whisper==20230117)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230117) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230117) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230117) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230117) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->openai-whisper==20230117) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->openai-whisper==20230117) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.19.0->openai-whisper==20230117) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230117) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230117) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230117) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230117) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230117) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230117-py3-none-any.whl size=1178610 sha256=dda91d60db224abf4e2efae704a0b51b63d25fd59de407fd8b2ea1467df13455\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/4d/1a/ad5530800c07d2409dc8dfd0a26ea5068f10f14c0060142b8a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tokenizers, safetensors, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n",
            "  Attempting uninstall: openai-whisper\n",
            "    Found existing installation: openai-whisper 20230314\n",
            "    Uninstalling openai-whisper-20230314:\n",
            "      Successfully uninstalled openai-whisper-20230314\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.16.4 openai-whisper-20230117 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install whisper\n",
        "!pip install openai-whisper==20230117"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "T3iB8FwGWx3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('large')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmlvHprTW1J-",
        "outputId": "833febff-9da0-46dd-aa16-ef4d22e831bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [01:04<00:00, 48.2MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n1TtCNCYHhJ",
        "outputId": "3b2e8388-f5bc-43e3-ca2b-38a0ee935e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "23DgmcY1YO4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "def enhance_audio(input_path, output_path, threshold=-20.0, ratio=3.0, attack=5, release=50, cutoff_frequency=3000):\n",
        "    # Load the audio using pydub\n",
        "    audio = AudioSegment.from_file(input_path)\n",
        "\n",
        "    # Apply dynamic range compression\n",
        "    audio_compressed = audio.compress_dynamic_range(threshold=threshold, ratio=ratio, attack=attack, release=release)\n",
        "\n",
        "    # Convert AudioSegment to numpy array\n",
        "    samples = np.array(audio_compressed.get_array_of_samples())\n",
        "\n",
        "    # Apply low-pass filtering\n",
        "    nyquist = audio.frame_rate / 2\n",
        "    low = cutoff_frequency / nyquist\n",
        "    b, a = butter(4, low, btype='low')\n",
        "    samples_filtered = lfilter(b, a, samples)\n",
        "\n",
        "    # Create a new AudioSegment with the filtered samples\n",
        "    audio_filtered = AudioSegment(\n",
        "        samples_filtered.tobytes(),\n",
        "        frame_rate=audio.frame_rate,\n",
        "        sample_width=audio.sample_width,\n",
        "        channels=audio.channels\n",
        "    )\n",
        "\n",
        "    # Save the enhanced audio\n",
        "    audio_filtered.export(output_path, format=\"wav\")\n",
        "\n",
        "# Replace 'input.wav' with the path to your input audio file (e.g., in WAV format).\n",
        "# Replace 'enhanced_output.wav' with your desired enhanced audio output path.\n",
        "enhance_audio(\"/content/ptp_Audio_1545802915132.3gp\", \"enhanced_output.wav\")\n"
      ],
      "metadata": {
        "id": "ZyKnkwsKW3wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def increase_audio_volume(input_path, output_path, gain_db=15.0):\n",
        "    # Load the audio using pydub\n",
        "    audio = AudioSegment.from_file(input_path)\n",
        "\n",
        "    # Apply gain to the audio\n",
        "    audio_louder = audio + gain_db\n",
        "\n",
        "    # Export the enhanced audio\n",
        "    audio_louder.export(output_path, format=\"wav\")\n",
        "\n",
        "# Replace 'input.wav' with the path to your input audio file (e.g., in WAV format).\n",
        "# Replace 'enhanced_output.wav' with your desired enhanced audio output path.\n",
        "increase_audio_volume(\"/content/ptp_Audio_1545802915132.3gp\", \"enhanced_output2.3gp\")\n"
      ],
      "metadata": {
        "id": "bjyaroama476"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=model.transcribe(\"/content/WhatsApp Audio 2023-08-11 at 22.04.47.dat.unknown\",task='translate')\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESC6BmzsdIZS",
        "outputId": "2c870e0e-3e12-4c82-a211-4e5d3a292585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \" God, this call is now being recorded. Yes. What was I saying? What was I saying? Did you see that drug? Whose? Did you see that drug? Which drug? The same one. Paracetamol? Yes, not Paracetamol. Benadryl. Oh, Benadryl. What happened to it? It's the best medicine for sleeping. It's the best? I'll have to use it. I can't sleep. You'll sleep. You'll sleep. What do you want to do with this? You can take 10-15 pills at a time. Okay. Should I take it too? Then I'll be in the hospital. For sure. For sure. Okay. You can close it now.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 2.0, 'text': ' God, this call is now being recorded.', 'tokens': [1265, 11, 341, 818, 307, 586, 885, 8287, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 1, 'seek': 0, 'start': 2.0, 'end': 3.0, 'text': ' Yes.', 'tokens': [1079, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 2, 'seek': 0, 'start': 3.0, 'end': 4.0, 'text': ' What was I saying?', 'tokens': [708, 390, 286, 1566, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 3, 'seek': 0, 'start': 4.0, 'end': 5.0, 'text': ' What was I saying?', 'tokens': [708, 390, 286, 1566, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 4, 'seek': 0, 'start': 5.0, 'end': 6.0, 'text': ' Did you see that drug?', 'tokens': [2589, 291, 536, 300, 4110, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 5, 'seek': 0, 'start': 6.0, 'end': 7.0, 'text': ' Whose?', 'tokens': [28463, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 6, 'seek': 0, 'start': 7.0, 'end': 9.0, 'text': ' Did you see that drug?', 'tokens': [2589, 291, 536, 300, 4110, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 7, 'seek': 0, 'start': 9.0, 'end': 10.0, 'text': ' Which drug?', 'tokens': [3013, 4110, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 8, 'seek': 0, 'start': 10.0, 'end': 12.0, 'text': ' The same one.', 'tokens': [440, 912, 472, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 9, 'seek': 0, 'start': 12.0, 'end': 14.0, 'text': ' Paracetamol?', 'tokens': [3457, 326, 302, 335, 401, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 10, 'seek': 0, 'start': 14.0, 'end': 16.0, 'text': ' Yes, not Paracetamol.', 'tokens': [1079, 11, 406, 3457, 326, 302, 335, 401, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 11, 'seek': 0, 'start': 16.0, 'end': 17.0, 'text': ' Benadryl.', 'tokens': [3964, 345, 627, 75, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 12, 'seek': 0, 'start': 17.0, 'end': 18.0, 'text': ' Oh, Benadryl.', 'tokens': [876, 11, 3964, 345, 627, 75, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 13, 'seek': 0, 'start': 18.0, 'end': 20.0, 'text': ' What happened to it?', 'tokens': [708, 2011, 281, 309, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 14, 'seek': 0, 'start': 20.0, 'end': 23.0, 'text': \" It's the best medicine for sleeping.\", 'tokens': [467, 311, 264, 1151, 7195, 337, 8296, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 15, 'seek': 0, 'start': 23.0, 'end': 24.0, 'text': \" It's the best?\", 'tokens': [467, 311, 264, 1151, 30], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 16, 'seek': 0, 'start': 24.0, 'end': 26.0, 'text': \" I'll have to use it.\", 'tokens': [286, 603, 362, 281, 764, 309, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 17, 'seek': 0, 'start': 26.0, 'end': 27.0, 'text': \" I can't sleep.\", 'tokens': [286, 393, 380, 2817, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 18, 'seek': 0, 'start': 27.0, 'end': 28.0, 'text': \" You'll sleep.\", 'tokens': [509, 603, 2817, 13], 'temperature': 0.0, 'avg_logprob': -0.3723333398778955, 'compression_ratio': 1.705, 'no_speech_prob': 0.6058447957038879}, {'id': 19, 'seek': 2800, 'start': 28.0, 'end': 30.0, 'text': \" You'll sleep.\", 'tokens': [509, 603, 2817, 13], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 20, 'seek': 2800, 'start': 30.0, 'end': 32.0, 'text': ' What do you want to do with this?', 'tokens': [708, 360, 291, 528, 281, 360, 365, 341, 30], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 21, 'seek': 2800, 'start': 32.0, 'end': 34.0, 'text': ' You can take 10-15 pills at a time.', 'tokens': [509, 393, 747, 1266, 12, 5211, 23871, 412, 257, 565, 13], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 22, 'seek': 2800, 'start': 34.0, 'end': 35.0, 'text': ' Okay.', 'tokens': [1033, 13], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 23, 'seek': 2800, 'start': 35.0, 'end': 37.0, 'text': ' Should I take it too?', 'tokens': [6454, 286, 747, 309, 886, 30], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 24, 'seek': 2800, 'start': 37.0, 'end': 39.0, 'text': \" Then I'll be in the hospital.\", 'tokens': [1396, 286, 603, 312, 294, 264, 4530, 13], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 25, 'seek': 2800, 'start': 39.0, 'end': 41.0, 'text': ' For sure.', 'tokens': [1171, 988, 13], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 26, 'seek': 2800, 'start': 41.0, 'end': 42.0, 'text': ' For sure.', 'tokens': [1171, 988, 13], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 27, 'seek': 2800, 'start': 42.0, 'end': 43.0, 'text': ' Okay.', 'tokens': [1033, 13], 'temperature': 0.0, 'avg_logprob': -0.6049747212727865, 'compression_ratio': 1.2847222222222223, 'no_speech_prob': 0.01162052433937788}, {'id': 28, 'seek': 4300, 'start': 43.0, 'end': 58.0, 'text': ' You can close it now.', 'tokens': [50364, 509, 393, 1998, 309, 586, 13, 51114], 'temperature': 0.0, 'avg_logprob': -0.8567687140570747, 'compression_ratio': 0.7241379310344828, 'no_speech_prob': 0.1072673499584198}], 'language': 'hi'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "zSaSuxQTdqw_",
        "outputId": "8339136d-5747-47a8-c651-8375c77b2f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" God, this call is now being recorded. Yes. What was I saying? What was I saying? Did you see that drug? Whose? Did you see that drug? Which drug? The same one. Paracetamol? Yes, not Paracetamol. Benadryl. Oh, Benadryl. What happened to it? It's the best medicine for sleeping. It's the best? I'll have to use it. I can't sleep. You'll sleep. You'll sleep. What do you want to do with this? You can take 10-15 pills at a time. Okay. Should I take it too? Then I'll be in the hospital. For sure. For sure. Okay. You can close it now.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=model.transcribe(\"/content/WhatsApp Audio 2023-08-11 at 22.04.47.dat.unknown\")\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ-WrnDPdoou",
        "outputId": "6edea6d5-9c52-4946-ba91-9173bc628a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ' अरे जैसे पर प्राजादा क्या करने का बीच जैसे टव़ पंडर डोलो और एक साथ ले ले ले गा अच्छा वैसा मैं भी ले लो क्या पिर सीधा हॉस्पिटल में ही सीधा आख खुले गे या डूट फ़ोशा फ़ोशा बराबर बराबर अपन खर दें', 'segments': [{'id': 0, 'seek': 3000, 'start': 30.0, 'end': 40.0, 'text': ' अरे जैसे पर प्राजादा क्या करने का बीच जैसे टव़ पंडर डोलो और एक साथ ले ले ले गा अच्छा वैसा मैं भी ले लो क्या पिर सीधा हॉस्पिटल में ही सीधा आख खुले गे', 'tokens': [8485, 227, 25411, 21981, 8485, 250, 43372, 45938, 21981, 8485, 103, 25411, 8485, 103, 27099, 25411, 17937, 3941, 250, 17937, 3941, 99, 17937, 31970, 27099, 48268, 17937, 31970, 25411, 35082, 21981, 31970, 17937, 8485, 105, 31881, 3941, 248, 8485, 250, 43372, 45938, 21981, 8485, 253, 3941, 113, 3941, 120, 8485, 103, 31945, 3941, 94, 25411, 8485, 94, 33926, 46758, 33926, 8485, 242, 25411, 8485, 237, 41858, 49316, 17937, 3941, 98, 8485, 110, 21981, 8485, 110, 21981, 8485, 110, 21981, 8485, 245, 17937, 8485, 227, 3941, 248, 27099, 3941, 249, 17937, 8485, 113, 43372, 45938, 17937, 48449, 43372, 31945, 8485, 255, 31881, 8485, 110, 21981, 8485, 110, 33926, 31970, 27099, 48268, 17937, 8485, 103, 33279, 25411, 49316, 31881, 3941, 100, 17937, 37139, 8703, 231, 45938, 27099, 3941, 103, 33279, 3941, 253, 46758, 48449, 21981, 31945, 37139, 31881, 49316, 31881, 3941, 100, 17937, 8485, 228, 3941, 244, 8485, 244, 8703, 223, 46758, 21981, 8485, 245, 21981], 'temperature': 0.0, 'avg_logprob': -0.48231468881879536, 'compression_ratio': 2.3031674208144794, 'no_speech_prob': 0.6270171403884888}, {'id': 1, 'seek': 4000, 'start': 40.0, 'end': 58.0, 'text': ' या डूट फ़ोशा फ़ोशा बराबर बराबर अपन खर दें', 'tokens': [50364, 8485, 107, 17937, 8485, 94, 8703, 224, 3941, 253, 8485, 104, 3941, 120, 33926, 3941, 114, 17937, 8485, 104, 3941, 120, 33926, 3941, 114, 17937, 8485, 105, 25411, 17937, 3941, 105, 25411, 8485, 105, 25411, 17937, 3941, 105, 25411, 8485, 227, 3941, 103, 35082, 8485, 244, 25411, 8485, 99, 21981, 3941, 224, 51264], 'temperature': 0.0, 'avg_logprob': -0.45186431191184306, 'compression_ratio': 1.5070422535211268, 'no_speech_prob': 0.07592340558767319}], 'language': 'hi'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QIVNW_oHdssZ",
        "outputId": "01bf0146-2cb0-4732-d302-9186bcca6682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' अरे जैसे पर प्राजादा क्या करने का बीच जैसे टव़ पंडर डोलो और एक साथ ले ले ले गा अच्छा वैसा मैं भी ले लो क्या पिर सीधा हॉस्पिटल में ही सीधा आख खुले गे या डूट फ़ोशा फ़ोशा बराबर बराबर अपन खर दें'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}